<?xml version="1.0" encoding="UTF-8"?>
<document>
  <content>
    <headers initialCol="1" llx="49.0" lly="337.0" urx="548.0" ury="753.0" pageNum="1" headerID="p1x58.0y734.0">
      <title initialCol="1" llx="58.0" lly="721.0" urx="548.0" ury="753.0" pageNum="1">STOCHASTIC PRONUNCIATION MODELLING FROM HAND-LABELLED PHONETIC CORPORA</title>
      <authors initialCol="1" llx="88.0" lly="679.0" urx="519.0" ury="711.0" pageNum="1">
        <author initialCol="1" llx="88.0" lly="693.0" urx="196.0" ury="711.0" pageNum="1">
          <author-first initialCol="1" llx="88.0" lly="693.0" urx="142.0" ury="711.0" pageNum="1">M.</author-first>
          <author-last initialCol="1" llx="88.0" lly="693.0" urx="142.0" ury="711.0" pageNum="1">Riley</author-last>
          <note initialCol="1" llx="130.0" lly="693.0" urx="196.0" ury="711.0" pageNum="1">1 ,</note>
        </author>
        <author initialCol="1" llx="133.0" lly="693.0" urx="250.0" ury="711.0" pageNum="1">
          <author-first initialCol="1" llx="133.0" lly="693.0" urx="196.0" ury="711.0" pageNum="1">W.</author-first>
          <author-last initialCol="1" llx="133.0" lly="693.0" urx="196.0" ury="711.0" pageNum="1">Byrne</author-last>
          <note initialCol="1" llx="184.0" lly="693.0" urx="250.0" ury="711.0" pageNum="1">2 ,</note>
        </author>
        <author initialCol="1" llx="187.0" lly="693.0" urx="328.0" ury="711.0" pageNum="1">
          <author-first initialCol="1" llx="187.0" lly="693.0" urx="250.0" ury="711.0" pageNum="1">M.</author-first>
          <author-last initialCol="1" llx="187.0" lly="693.0" urx="250.0" ury="711.0" pageNum="1">Finke</author-last>
          <note initialCol="1" llx="238.0" lly="693.0" urx="328.0" ury="711.0" pageNum="1">3 ,</note>
        </author>
        <author initialCol="1" llx="241.0" lly="693.0" urx="380.0" ury="711.0" pageNum="1">
          <author-first initialCol="1" llx="241.0" lly="693.0" urx="328.0" ury="711.0" pageNum="1">S.</author-first>
          <author-last initialCol="1" llx="241.0" lly="693.0" urx="328.0" ury="711.0" pageNum="1">Khudanpur</author-last>
          <note initialCol="1" llx="315.0" lly="693.0" urx="380.0" ury="711.0" pageNum="1">2 ,</note>
        </author>
        <author initialCol="1" llx="318.0" lly="693.0" urx="461.0" ury="711.0" pageNum="1">
          <author-first initialCol="1" llx="318.0" lly="693.0" urx="380.0" ury="711.0" pageNum="1">A.</author-first>
          <author-last initialCol="1" llx="318.0" lly="693.0" urx="380.0" ury="711.0" pageNum="1">Ljolje</author-last>
          <note initialCol="1" llx="367.0" lly="693.0" urx="461.0" ury="711.0" pageNum="1">1 ,</note>
        </author>
        <author initialCol="1" llx="370.0" lly="693.0" urx="511.0" ury="711.0" pageNum="1">
          <author-first initialCol="1" llx="370.0" lly="693.0" urx="461.0" ury="711.0" pageNum="1">J.</author-first>
          <author-last initialCol="1" llx="370.0" lly="693.0" urx="461.0" ury="711.0" pageNum="1">McDonough</author-last>
          <note initialCol="1" llx="449.0" lly="693.0" urx="511.0" ury="711.0" pageNum="1">2 ,</note>
        </author>
        <author initialCol="1" llx="452.0" lly="693.0" urx="519.0" ury="711.0" pageNum="1">
          <author-first initialCol="1" llx="452.0" lly="693.0" urx="511.0" ury="711.0" pageNum="1">H.</author-first>
          <author-last initialCol="1" llx="452.0" lly="693.0" urx="511.0" ury="711.0" pageNum="1">Nock</author-last>
          <note initialCol="1" llx="499.0" lly="693.0" urx="519.0" ury="711.0" pageNum="1">4 ,</note>
        </author>
        <author initialCol="1" llx="191.0" lly="679.0" urx="327.0" ury="697.0" pageNum="1">
          <author-first initialCol="1" llx="191.0" lly="679.0" urx="263.0" ury="697.0" pageNum="1">M.</author-first>
          <author-last initialCol="1" llx="191.0" lly="679.0" urx="263.0" ury="697.0" pageNum="1">Saraclar</author-last>
          <note initialCol="1" llx="251.0" lly="679.0" urx="327.0" ury="697.0" pageNum="1">3 ,</note>
        </author>
        <author initialCol="1" llx="254.0" lly="679.0" urx="411.0" ury="697.0" pageNum="1">
          <author-first initialCol="1" llx="254.0" lly="679.0" urx="327.0" ury="697.0" pageNum="1">C.</author-first>
          <author-last initialCol="1" llx="254.0" lly="679.0" urx="327.0" ury="697.0" pageNum="1">Wooters</author-last>
          <note initialCol="1" llx="314.0" lly="679.0" urx="411.0" ury="697.0" pageNum="1">5 ,</note>
        </author>
        <author initialCol="1" llx="317.0" lly="679.0" urx="411.0" ury="697.0" pageNum="1">
          <author-first initialCol="1" llx="317.0" lly="679.0" urx="411.0" ury="697.0" pageNum="1">G.</author-first>
          <author-last initialCol="1" llx="317.0" lly="679.0" urx="411.0" ury="697.0" pageNum="1">Zavaliagkos</author-last>
          <note initialCol="1" llx="398.0" lly="686.0" urx="406.0" ury="692.0" pageNum="1">6</note>
        </author>
      </authors>
      <institution initialCol="1" llx="177.0" lly="652.0" urx="424.0" ury="670.0" pageNum="1">AT&amp;T Labs -- Research,</institution>
      <address initialCol="1" llx="177.0" lly="652.0" urx="424.0" ury="670.0" pageNum="1">Florham Park, NJ, USA</address>
      <note initialCol="1" llx="413.0" lly="659.0" urx="420.0" ury="665.0" pageNum="1">1</note>
      <institution initialCol="1" llx="178.0" lly="639.0" urx="423.0" ury="656.0" pageNum="1">Johns Hopkins University,</institution>
      <address initialCol="1" llx="178.0" lly="639.0" urx="423.0" ury="656.0" pageNum="1">Baltimore, MD, USA</address>
      <note initialCol="1" llx="412.0" lly="645.0" urx="420.0" ury="652.0" pageNum="1">2</note>
      <institution initialCol="1" llx="174.0" lly="625.0" urx="427.0" ury="643.0" pageNum="1">Carnegie-Mellon University,</institution>
      <address initialCol="1" llx="174.0" lly="625.0" urx="427.0" ury="643.0" pageNum="1">Pittsburgh, PA, USA</address>
      <note initialCol="1" llx="416.0" lly="632.0" urx="423.0" ury="638.0" pageNum="1">3</note>
      <institution initialCol="1" llx="139.0" lly="612.0" urx="462.0" ury="630.0" pageNum="1">Cambridge University Engineering Department, Cambridge,</institution>
      <address initialCol="1" llx="139.0" lly="599.0" urx="462.0" ury="630.0" pageNum="1">UK 4 U.S. Department of Defense, Fort Meade, MD, USA</address>
      <note initialCol="1" llx="422.0" lly="605.0" urx="430.0" ury="611.0" pageNum="1">5</note>
      <institution initialCol="1" llx="224.0" lly="585.0" urx="377.0" ury="603.0" pageNum="1">BBN,</institution>
      <address initialCol="1" llx="224.0" lly="585.0" urx="377.0" ury="603.0" pageNum="1">Cambridge, MA, USA 6</address>
      <abstract initialCol="1" llx="49.0" lly="337.0" urx="299.0" ury="563.0" pageNum="1">ABSTRACT In the early '90s, the availability of the TIMIT read-speech phonetically transcribed corpus led to work at AT&amp;T on the automatic inference of pronunciation variation. This work, briefly summarized here, used stochastic decisions trees trained on phonetic and linguistic features, and was applied to the DARPA North American Business News read-speech ASR task. More recently, the ICSI spontaneous-speechphonetically transcribed corpus was collected at the behest of the 1996 and 1997 LVCSR Summer Workshops held at Johns Hopkins University. A 1997 workshop (WS97) group focused on pronunciation inference from this corpus for application to the DoD Switchboard spontaneous telephone speech ASR task. We describe several approaches taken there. Theseinclude (1) oneanalogousto the AT&amp;T approach, (2) one, inspired by work at WS96 and CMU, that involved adding pronunciation variants of a sequence of one or more words (`multiwords') in the corpus (with corpus-derived probabilities) into the ASR lexicon, and (1+2) a hybrid approachin which a decision-tree model was used to automatically phonetically transcribe a much larger speech corpus than ICSI and then the multiword approach was used to construct an ASR recognition pronunciation lexicon.</abstract>
    </headers>
    <body initialCol="1" llx="49.0" lly="126.0" urx="570.0" ury="771.0" pageNum="1" bodyID="p1x125.0y312.0">
      <section-marker initialCol="1" llx="125.0" lly="312.0" urx="220.0" ury="327.0" pageNum="1">1. INTRODUCTION</section-marker>
      <text initialCol="1" llx="49.0" lly="126.0" urx="296.0" ury="306.0" pageNum="1">Most speech recognition systems rely on pronouncing dictionaries that contain few alternate pronunciationsfor most words. In natural speech, however, words seldom adhere to their citation forms. The failure of ASR systems to capture this important source of variability is potentially a significant source for recognition errors, particularly in spontaneous, conversational speech. We report methods used to address this issue applied to read speech at AT&amp;T [9] and to spontaneous speech at and after WS97, the Fifth LVCSR Summer Workshop, held at Johns Hopkins University, Baltimore, in JulyAugust, 1997 [2]. As a first step towards alleviating this common limitation of pronouncing dictionaries, we identify a systematic way of generating alternate pronunciations of words by using phonetically labelled portions of the TIMIT [5] and Switchboard [6] corpora. One viewpoint we explore is that pronunciation variability may be modelled by a statistical mapping from canonical pronunciations (baseforms) to symbolic surface forms, and we use decision trees to</text>
      <text initialCol="1" llx="308.0" lly="126.0" urx="565.0" ury="562.0" pageNum="1">capture this mapping. A second way we exploit the hand transcriptions is by enhancing the dictionary using frequently seen pronunciations. While the former has the potential to generalize to unseen words and pronunciations, the latter is more conservative and hence potentially more robust. As many researchers haveobserved earlier, simply adding several alternate pronunciations to the dictionary increases the confusability of words to the extent that the gains from havingthem are often more than nullified. We address this problem in two ways. We assign costs to alternate pronunciations so that, e.g., if a frequent pronunciation of "cause" and an infrequent pronunciation of "because" are identical, a penalty is incurred to attribute the pronunciation to "because" rather than "cause." In addition, we account for context effects so that, e.g., "to" is allowed the pronunciation [ax], which is a frequent pronunciation of "a," only if "to" is preceded by "going," as in [g aa n ax]. Our pronunciation modelling efforts may be divided into two broad categories. In our tree based dictionary expansion experiments, we apply decision tree based pronunciationmodels to entries in our baseform dictionary to obtain alternate pronunciations, which are then used in testing. In our explicit dictionary expansion experiments, we apply the decision tree based pronunciation models first to the training corpus, and perform a forced alignment with the acoustic models to "choose"amongst the alternatives. The dictionary is then explicitly augmented with novel pronunciations which occur sufficiently often. The tree based expansion implicitly adds manymorenew pronunciations than the explicit expansion. However, it does not attempt to model any cross-word coarticulation. The explicit expansion does so by allowing as dictionary entries a select set (cf. [4]) of multiwords -- word pairs and triples. We demonstrate in Sections 2 and 3 that the tree-based method gives a reduction in the word error rate (WER) for the read-speech North American Business (NAB) News task while both methods give reductions for the conversationaltelephonespeechSwitchboard task over baseline systems using only a citation-form dictionary. Further, we show in Sections 4 and 5 that reductions persist when the baselinesystems are improvedby coarticulation sensitive acoustic modelling and improved language modelling.</text>
      <section-marker initialCol="1" llx="75.0" lly="756.0" urx="269.0" ury="771.0" pageNum="2">2. TREE BASED DICTIONARY EXPANSION</section-marker>
      <text initialCol="1" llx="49.0" lly="694.0" urx="297.0" ury="750.0" pageNum="2">Our tree basedpronunciation modelswere inspired by phonological rules in acoustic phonetic studies (cf., e.g., [7]) which characterize allophonic variations in certain phonemic contexts, and by the successful use of similar methods to model pronunciation variability and constraints by other researchers (e.g., [3, 8, 4, 10, 12, 11]).</text>
      <figure-marker initialCol="1" llx="49.0" lly="637.0" urx="295.0" ury="698.0" pageNum="2">Figure 1 illustrates the deletion or alteration of a phoneme in context which we modelled via decision trees. I HAVE FORMULATED A ay hh ae v f ow r m y ax l ey t ih d ax</figure-marker>
      <text initialCol="1" llx="75.0" lly="563.0" urx="299.0" ury="574.0" pageNum="2">ay v_vl f ao r m ih_n l ey dx_t ih dx_d ax f f f</text>
      <figure-marker initialCol="1" llx="49.0" lly="489.0" urx="258.0" ury="545.0" pageNum="2">Figure 1: Decision Trees as Phone Predictors 2.1. Decision Trees from Hand Labelled Data</figure-marker>
      <text initialCol="1" llx="49.0" lly="137.0" urx="308.0" ury="486.0" pageNum="2">The decision trees built for these tasks drew from a substantial portion (134,000 phones) of the TIMIT data set and approximately 3.5 hours (96,000 phones) of the phonetically labelled transcriptions of the Switchboard (ICSI) data set. The labels used by the annotators were slightly richer than the phonetic labels in the pronouncing dictionary (PronLex) used for these experiments. However, since the acoustic models for the baseline system were trained using the PronLex phone set, the hand annotations were mapped down to this phone set for reasons of consistency. Next, basedon the orthographic transcriptions and the pronouncing dictionary, a phonemic transcription of the utterances was obtained. Whenever the dictionary permitted more than one pronunciation for a word, a choice was made via a forced alignment of the acoustic signal with the alternatives using the baseline acoustic models. The phonemic transcriptions were then lined up with the phonetic labels, using as the alignment criterion the minimization of the phonetic feature distance betweenthe two symbol streams [9]. Table 1 gives an example alignment from the ICSI corpus. This gave us a corpus of phoneme-to-phone transformations together with the phonemic environment or context for each instance. Decision tree models were then built to represent this phoneme to phone mapping. The context included the identity of the phoneme to be mapped as well as three neighbouring phonemes on either side (each encoded in terms of its phonetic features -- see Table 2), the lexical stress on neighbouringvowels as obtainedfrom the pronouncing dictionary, and the distance of the phoneme from the nearest segment boundary on either side, where the segment could be either a syllable, a word or a phrase. A separate tree was grown for each phoneme. The tree growing criterion was minimization of the empirical entropy of the surface phone, the stopping criterion wasaminimum samplecount at both parent and child nodes,</text>
      <notext initialCol="1" llx="49.0" lly="126.0" urx="518.0" ury="720.0" pageNum="2">and the trees were pruned via internal fivefold cross-validation. PHONEME PHONE WORD f f for ao ao r dh dh the ax iy f f for ao r dh dh the ax ax d jh drug r r ah ah g g</notext>
      <table-marker initialCol="1" llx="325.0" lly="261.0" urx="555.0" ury="553.0" pageNum="2">Table 1: Phoneme-to-phone Alignment. ffl Consonant-Manner: voiced stop, unvoiced stop, voiced fricative, unvoiced fricative, voiced affricate, unvoiced affricate, nasal, rhotic, lateral, not--applicable. ffl Consonant-Place: bilabial, labiodental, dental, alveolar, palatal, velar, pharyngeal, not--applicable. ffl Vowel-Manner: monophthong, r--colored vowel, w--diphthong, y--diphthong, glide, not--applicable . ffl Vowel-Place : front--low, front--mid--low, front--high, central--mid--low, central--mid--high, back--low, back--mid--low, back--mid-high, back--high, not--applicable.</table-marker>
      <table-marker initialCol="1" llx="308.0" lly="182.0" urx="555.0" ury="248.0" pageNum="2">Table 2: Phoneme Encoding Scheme. Each phoneme is represented as a four-element feature vector, (consonant-manner, consonant-place, vowel-manner, vowel-place). For example, /s/ is encoded as (voiceless fricative, palatal, n/a, n/a) and /iy/ is encoded as (n/a, n/a, y-diphthong, high-front).</table-marker>
      <notext initialCol="1" llx="60.0" lly="642.0" urx="283.0" ury="763.0" pageNum="3">Training Data Average log 2 -prob (Efficiency) ICSI-test TIMIT-test TIMIT 0.76 ! 0.60 (20%) 0.34 ! 0.17 (51%) ICSI 0.72 ! 0.50 (30%) ICSI+TIMIT 0.71 ! 0.48 (32%) Table 3: Prediction Entropy for Pronunciation Trees 2.1.1. Predicting Surface Forms from Baseforms</notext>
      <text initialCol="1" llx="49.0" lly="448.0" urx="299.0" ury="639.0" pageNum="3">Each leaf in a tree thus assigned probabilities in some context to more than one surface form realization of the phoneme it modelled. A way to judge the goodness of these trees, therefore, was to apply them as predictors on a held out portion of the hand labelled corpora. Test sets from TIMIT and ICSI corpora were held out for this purpose. The results in Table 3 summarize the predictive ability of the trees on these sets. 1 Relative to the context independent distribution of surface form realizations of a phoneme, decision trees built on the TIMIT portion of the trainig set reduce the entropy by about 50%, when tested on TIMIT. Those built on the Switchboard portion of the training set reduce the entropy by about 30%, when tested on Switchboard. Trees based on TIMIT alone are much less effective on the Switchboard test set (20%), but adding them to the Switchboard training data (ICSI+TIMIT) results in a small additional gain (32%). These results suggest there is more variability in pronunciationsin Switchboard, relative to TIMIT, which is not captured by either the phonemiccontext cuesor the modellingparadigm we considered.</text>
      <section-marker initialCol="1" llx="64.0" lly="425.0" urx="227.0" ury="438.0" pageNum="3">2.1.2. The Effect of Leaving Out Features</section-marker>
      <text initialCol="1" llx="49.0" lly="315.0" urx="296.0" ury="422.0" pageNum="3">In order to investigate the conditional utility of each of our contextual features given the others, trees were built at WS97 by leaving features out from the context one at a time. Table 4 summarizes the results of these experiments. The trees were trained on all of the Switchboard and TIMIT data mentioned above, and the test set was the same as the one used for the Switchboard results of Table 3. Note that, at least for this corpus size, there was little additional predictive power in neighbouring phonemes more than one position away, when the triphone context, word boundary, and lexical stress related information was specified.</text>
      <section-marker initialCol="1" llx="64.0" lly="291.0" urx="246.0" ury="304.0" pageNum="3">2.1.3. The Impact of Some Additional Features</section-marker>
      <text initialCol="1" llx="49.0" lly="264.0" urx="295.0" ury="288.0" pageNum="3">We also experimented at WS97 with adding new features to the decision trees.</text>
      <notext initialCol="1" llx="66.0" lly="249.0" urx="295.0" ury="263.0" pageNum="3">ffl Based on the number of distinct pronunciations of a word</notext>
      <text initialCol="1" llx="74.0" lly="187.0" urx="295.0" ury="252.0" pageNum="3">that were seen in the ICSI-portion of the corpus, words were categorized into ten bins: from words having many pronunciations to words having few pronunciations. The bin number was then provided to the trees for each phoneme of the word. It was hoped that knowing how stable a word's pronunciation was would help predict the surface form better.</text>
      <notext initialCol="1" llx="66.0" lly="172.0" urx="295.0" ury="186.0" pageNum="3">ffl It is varyingly conjectured that frequently used words,</notext>
      <text initialCol="1" llx="74.0" lly="162.0" urx="295.0" ury="176.0" pageNum="3">function words or low information bearing words often tend to</text>
      <notext initialCol="1" llx="49.0" lly="127.0" urx="542.0" ury="763.0" pageNum="3">1 So that test observations in contexts unseen in training do not make entropy figures infinite, the worst 10% of the test data (i.e., highest log 2 -prob) is removed from each entropy measurement in this paper. Features Provided as Context log 2 -prob</notext>
      <text initialCol="1" llx="321.0" lly="616.0" urx="535.0" ury="750.0" pageNum="3">All Features 0.485 x 3rd Phoneme y Excluded 0.484 x 2nd and 3rd Phonemes y Excluded 0.485 Lexical Stress Excluded 0.487 Segment Boundary Cue Excluded 0.490 Vowels (manner and place) Excluded 0.497 Stress and Segment Boundary Cues Excluded 0.498 Consonants (manner, place) Excluded 0.527 Right Phonemic Context Excluded 0.537 Left Phonemic Context Excluded 0.547 Entire Phonemic Context Excluded 0.606 All Context Excluded (root trees) 0.714</text>
      <table-marker initialCol="1" llx="323.0" lly="474.0" urx="540.0" ury="609.0" pageNum="3">Table 4: Leaving Out Features from the Context Features Added to Context log 2 -prob None 0.485 Word level Pronunciation Variance (10 bins) 0.481 Word Frequency (from 60 hr training) 0.483 Pron. Variance and Word Frequency 0.483 Pron. Var., Word Freq., and Previous Phone 0.451 Table 5: Adding New Features to the Context</table-marker>
      <notext initialCol="1" llx="325.0" lly="363.0" urx="555.0" ury="444.0" pageNum="3">be mispronounced. The frequency of occurrence of a word in the 60 hour acoustic training corpus was provided to the trees for each phoneme of the word. ffl In the hope of capturing limited phonotactics, as well as to indirectly model deletion or reduction of units larger than phonemes, the trees were provided the surface form realization of the previous phoneme.</notext>
      <text initialCol="1" llx="308.0" lly="274.0" urx="555.0" ury="361.0" pageNum="3">Table 5 summarizes our results. All the features used by the ICSI+ TIMIT trees of Table 3 are already present in the context. Note that while we were unable to successfully exploit the information about empirical pronunciation variability or frequency of a word, knowing the previous surface form seems to be of significant value in this modelling paradigm, perhaps because it compensates for some of our conditional independence assumptions in modelling the phoneme to phone mapping very locally.</text>
      <section-marker initialCol="1" llx="308.0" lly="247.0" urx="508.0" ury="262.0" pageNum="3">2.2. Generating Automatic Phone Transcriptions</section-marker>
      <text initialCol="1" llx="308.0" lly="126.0" urx="555.0" ury="244.0" pageNum="3">Using decision trees is a data intensive modelling technique. Large quantities of automatic phonetic transcriptions were generated to augment the hand-labelled corpora using the 37,000 training sentences (SI-284 training data set) for the NAB task at AT&amp;T and using the 60-hour acoustic training corpus for the Switchboard task at WS97. Unlike [11], where unconstrained phone recognition was used to generate phone transcriptions, we constrained the words in our training utterances to assumeonly pronunciations generated by application of the decision trees to their phonemic baseforms: a forced alignment was performed on the resulting network of alternate pronunciations in an utterance and the most likely sequence of</text>
      <notext initialCol="1" llx="84.0" lly="749.0" urx="260.0" ury="763.0" pageNum="4">Model # Trn tokens log 2 -prob</notext>
      <text initialCol="1" llx="84.0" lly="713.0" urx="252.0" ury="750.0" pageNum="4">ICSI+TIMIT 96,040 0.525 Recount Weights 2.36 million 0.585 Rebuild Trees 2.36 million 0.542</text>
      <section-marker initialCol="1" llx="63.0" lly="692.0" urx="281.0" ury="706.0" pageNum="4">Table 6: Rebuilding v/s Retuning the Pronunciation Trees</section-marker>
      <text initialCol="1" llx="49.0" lly="486.0" urx="304.0" ury="664.0" pageNum="4">pronunciations was chosen to be the phonetic transcription. Pronunciation probabilities derived from the trees were used as `language model' weights during alignment, and since the word transcription was provided, word level language model weights are redundant and were not used. Anecdotalevidencesuggeststhat this method of obtaining automatic transcriptions is reasonable: it agrees more with human annotations than the phonemic baseforms do, though not by much. For the hand labelled portion of the ICSI corpus, for instance, we aligned the baseforms with the hand labels and found the phone error rate of the citation form transcription to be about 30%. The error rate for the automatic transcriptions for the same portion was 25%. words just because they're grandparents ... dict jh ah s t b ax k ah z dh ey r g r ae n p ey r ih n t s</text>
      <notext initialCol="1" llx="55.0" lly="476.0" urx="304.0" ury="490.0" pageNum="4">icsi jh ah s t b ax k ah z dh ey r g r ae n p ey r ih n t s</notext>
      <text initialCol="1" llx="49.0" lly="394.0" urx="296.0" ury="480.0" pageNum="4">auto jh ax s b ax k ao z er g r ae n p eh r s It is also not clear if total agreement with the hand labels is desirable. Occasionally, as in the transcriptions shown above, a large number of human listeners preferred the automatic transcriptions to those of the annotators! Readers who would wish to listen to this particular utterance can find it on the 1997 LVCSR workshop pronunciation project web page at www.clsp.jhu.edu.</text>
      <section-marker initialCol="1" llx="64.0" lly="370.0" urx="297.0" ury="384.0" pageNum="4">2.2.1. Building Decision Trees from Automatic Transcriptions</section-marker>
      <text initialCol="1" llx="49.0" lly="177.0" urx="296.0" ury="367.0" pageNum="4">These transcriptions were used to build new decision trees. Two options were explored to use this large amount of training data -- retain the topology (i.e., the sequenceof questions, or the equivalence classification of the contexts) of the original phonetically hand labelled corpus trees, and only update their leaf distribution by pouring this new training data down those trees; or rebuild the trees altogether. When applied to Switchboard, there is very little differencebetween the two methods as far as prediction entropy on a held out set goes, as illustrated in Table 6. It is also not surprising that the prediction entropy of these trees is higher than the ICSI+TIMIT trees trained on hand labels alone, because there is an obvious mismatch between the automatic derivation of the training transcriptions, and the hand labelling of the test set. The fully rebuilt trees were named Retrained trees. Since we now had much more training data, we also built trees which additionally included in the context the previously realized surface form so as to capture some of the dependencyin the surface string. Trees built this way were named Retrained2 trees.</text>
      <section-marker initialCol="1" llx="49.0" lly="153.0" urx="265.0" ury="167.0" pageNum="4">2.3. Dictionary Expansion Using Pronunciation Trees</section-marker>
      <text initialCol="1" llx="49.0" lly="126.0" urx="295.0" ury="150.0" pageNum="4">We applied the ICSI+TIMIT trees of Table 3 to successive phonemes of each baseform in the WS97 baseline dictionary to obtain a</text>
      <notext initialCol="1" llx="389.0" lly="713.0" urx="473.0" ury="763.0" pageNum="4">Dictionary WER TTS 12.7% TIMIT 10.8% Retrained2 10.0%</notext>
      <table-marker initialCol="1" llx="316.0" lly="692.0" urx="547.0" ury="706.0" pageNum="4">Table 7: NAB recognition results with Enhanced Dictionaries</table-marker>
      <text initialCol="1" llx="308.0" lly="515.0" urx="555.0" ury="663.0" pageNum="4">weighted pronunciation network as described in [9]. Figure 2 illustrates sucha network for the word pretty. Applied statically, this p r ix ih ix ih t dx_t ix iy iy f f f pretty p r ih t iy</text>
      <figure-marker initialCol="1" llx="343.0" lly="491.0" urx="517.0" ury="507.0" pageNum="4">Figure 2: Pronunciation Network for pretty</figure-marker>
      <text initialCol="1" llx="308.0" lly="406.0" urx="555.0" ury="482.0" pageNum="4">resulted in an expanded dictionary which we call the ICSI+TIMIT dictionary. We also applied the Retrained trees to baseforms in the baseline dictionary as before, to obtain a secondenhanced dictionary, which we call the Retrained dictionary. Finally, expanding the baseforms in the baseline dictionary using the Retrained2 trees resulted in the Retrained2 dictionary.</text>
      <section-marker initialCol="1" llx="308.0" lly="379.0" urx="477.0" ury="394.0" pageNum="4">2.4. Testing with Tree Based Dictionaries</section-marker>
      <text initialCol="1" llx="308.0" lly="164.0" urx="555.0" ury="376.0" pageNum="4">At AT&amp;T, both trees built on TIMIT and retrained trees built on the automatically transcribed SI-284 training corpus were used to constuct recognition dictionaries for the NAB Eval '95 test set. These were compared with a baseline system whose pronunciations came from the AT&amp;T TTS text-to-speech system. Table 7 shows these recognition results. We see that the TIMIT-based trees gave a 1.9% WER reduction over the citation-form TTS dictionary, while trees retrained on the SI-284 training corpus gave an additional 0.8% reduction. In this earlier work, the full TIMIT phone set (minus the stop closures) was used, which contained 53 phones compared to the TTS inventory of 41 phonemes. Thus, new acoustic modelshad to be built for the larger phone set. In other words, the acoustic models used for the TIMIT and Retrained2 entries in Table 7 were different than the TTS-based test. At WS97, this was not required, since as mentioned before, the phone realizations had been forceably mapped to the PRONLEX set. At WS97, bigram lattices for the WS97 development-test were rescored using the enhanceddictionaries described above using the WS97 baseline acoustic models 2 . Table 8 shows recognition performance using the three static but weighted enhancements to the</text>
      <notext initialCol="1" llx="67.0" lly="127.0" urx="554.0" ury="763.0" pageNum="4">2 The baselineacoustic modelswere state clusteredcross-wordtriphones comprising about 7000 states, each with twelve-component Gaussian mixture output densities, trained on about sixty hours of Switchboard data. Dictionary WER DEL SUB INS Pronlex 44.66% 10.85% 29.47% 4.34% ICSI+TIMIT 46.14% 11.65% 30.39% 4.10% Retrained 43.99% 10.90% 29.08% 4.02% Retrained2 43.75% 10.87% 28.85% 4.02%</notext>
      <table-marker initialCol="1" llx="49.0" lly="574.0" urx="295.0" ury="695.0" pageNum="5">Table 8: Switchboard Recognition Results with Enhanced Dictionaries aries Dictionary Weights WER DEL SUB INS PronLex -- 44.66% 1987 5398 796 ICSI+TIMIT P = 1 46.14% 2134 5568 751 ICSI+TIMIT max = 1 46.13% 1904 5653 893 Table 9: Scaling Pronunciation Probabilities</table-marker>
      <text initialCol="1" llx="49.0" lly="335.0" urx="299.0" ury="546.0" pageNum="5">dictionary based on the ICSI+TIMIT trees, the Retrained trees and the Retrained2 trees. The degradationin performancefrom the ICSI+TIMIT dictionary came as a surprise, especially since the AT&amp;T NAB experiments showedan apparently opposite effect. There were, however, many differences between the two tests including (1) a read speech, low error task versus a spontaneousspeech,high error rate task, (2) the TTS-dictionary versus the PRONLEX dictionary, (3) 53 phone set versus a 43 phone set, (4) potentially different phonetic transcription conventions between the TIMIT and ICSI labellers, and (5) acoustic model retraining in the AT&amp;T experiments but not in the WS97 experiments. In fact, preliminary attempts at WS97 to retrain acousticmodels using tree-based pronunciationlexicons lead to significantly worse results [1]. There were various conjecturesmadewhy the ICSI+TIMIT dictionary gave a worse result and we launched an series of experiments to investigate them. These are described in the next few paragraphs. From Table 8, we also see that the Retrained and Retrained2 trees yielded modest but statistically significant improvements in word error rate over the WS97 baseline system.</text>
      <section-marker initialCol="1" llx="64.0" lly="311.0" urx="296.0" ury="325.0" pageNum="5">2.4.1. AreWords with Many PronunciationsBeing Penalized?</section-marker>
      <text initialCol="1" llx="49.0" lly="180.0" urx="296.0" ury="309.0" pageNum="5">It is conceivable that a word such as and, which admits many pronunciations, maybe unnecessarilypenalized relative to a word with few pronunciations such as an. e.g., the phones [ae n] are the most likely pronunciation for both an and and in conversational speech. Since they havea much higher likelihood amongstpronunciations of an than amongst those of and, other things being equal, it costs less to map these phonesto the word an. If Viterbi decoding is employed, many researchers have suggested that this problem is alleviated by scaling the pronunciation probabilities of every word so that the most likely pronunciation has unit weight 3 . We scaled our enhanced ICSI+TIMIT dictionary in this manner, and found an insignificant gain (see Table 9), ruling this out as</text>
      <notext initialCol="1" llx="49.0" lly="127.0" urx="295.0" ury="175.0" pageNum="5">3 This would perhaps be unnecessary if the likelihoods were properly summed over all pronunciations of a word, but is a sensible adjustment for Viterbi decoding, as is the additional scaling of the pronunciationprobabilities by the languagemodel scale (12) to bring them on par with the acoustic scores.</notext>
      <text initialCol="1" llx="319.0" lly="713.0" urx="543.0" ury="763.0" pageNum="5">Dictionary Context WER DEL SUB INS PronLex -- 44.66% 1987 5398 796 ICSI+TIMIT None 46.14% 2134 5568 751 ICSI+TIMIT 1 Phone 46.09% 2112 5590 743</text>
      <text initialCol="1" llx="308.0" lly="692.0" urx="555.0" ury="706.0" pageNum="5">Table 10: Word-Internal v/s Cross-Word Pronunciation Modelling</text>
      <section-marker initialCol="1" llx="319.0" lly="647.0" urx="545.0" ury="661.0" pageNum="5">Dictionary (# Expanded) WER DEL SUB INS</section-marker>
      <text initialCol="1" llx="308.0" lly="545.0" urx="554.0" ury="648.0" pageNum="5">PronLex 44.66% 1987 5398 796 ICSI+TIMIT (All Words) 46.14% 2134 5568 751 ICSI+TIMIT (Top 100) 45.50% 2213 5456 666 Table 11: Expanding Only the Most Frequent Words Using Trees the major cause of the degradation in performance.</text>
      <section-marker initialCol="1" llx="323.0" lly="512.0" urx="524.0" ury="526.0" pageNum="5">2.4.2. Do the Trees Badly Need Crossword Context?</section-marker>
      <text initialCol="1" llx="308.0" lly="346.0" urx="555.0" ury="506.0" pageNum="5">Recall that the enhanceddictionaries were obtained by applying the pronunciation trees to baseforms in isolation, and thus they could not utilize crossword context. We wrote additional software utilities so that the pronunciation model could be applied to the bigram lattices directly. However, looking at three neighbouringphonemes across word boundaries would have resulted in a drastic expansion of the lattice. We therefore implemented crossword pronunciation trees which looked at only one neighbouring phoneme in the context. This, we expected, would not be a severe limitation in light of the fact (from Table 4) that the deleted context is of little additional value in prediction. The results in Table 10 indicates that this too is not the entire reason for the poor performance of the ICSI+TIMIT dictionary. We conjecture that crossword pronunciation context is perhaps more important for some words than others (e.g., and I, want to).</text>
      <section-marker initialCol="1" llx="323.0" lly="314.0" urx="498.0" ury="328.0" pageNum="5">2.4.3. Are the Trees Generalizing Too Much?</section-marker>
      <text initialCol="1" llx="308.0" lly="126.0" urx="558.0" ury="308.0" pageNum="5">The motivation for using local decision tree based models is to be able to observe phoneme to phone transformations which are universally applicable. However, it may be argued that since many words exhibit remarkably stable pronunciationsin the handlabelled data set, the pronunciation model when applied to these words creates confusion without generating useful new pronunciations. We therefore expanded only the hundred most frequent words in the corpus using the ICSI+TIMIT trees, and tested using this instead of the ICSI+TIMIT dictionary. As the results in Table 11 indicate, this is a significant improvement over expanding all dictionary entries, and should be investigated further. However, this is still not the sole reason for the poor performance of the ICSI+TIMIT dictionary, as the performancecontinues to be below that baseline system. It may be argued, for instance, that expanding only the 100 most frequent words simply brings the system closer to the baseline, and the recognition performance tracks this regression.</text>
      <notext initialCol="1" llx="56.0" lly="483.0" urx="288.0" ury="763.0" pageNum="6">Pronunciation Probability ICSI+TIMIT Dictionary Empirical WANT TO: [w aa n t t ax] w aa n ax 0.04 0.34 w aa n t ax 0.20 0.28 w aa t t ax 0.05 -WANT TO: [w ah n t t ax] w ah n ax 0.05 0.37 w ah n t ax 0.26 -w ah n t ah 0.06 -Table 12: Empirical vs. ICSI+TIMIT Dictionary Probabilities Pronunciation Probability Retrained2 Dictionary Empirical WANT TO: [w aa n t t ax] w aa n ax 0.08 0.34 w aa n t ax 0.49 0.28 w aa n t uw 0.08 -WANT TO: [w ah n t t ax] w ah n ax 0.10 0.37 w ah n t ax 0.61 -w ah n t uw 0.10</notext>
      <section-marker initialCol="1" llx="62.0" lly="462.0" urx="282.0" ury="476.0" pageNum="6">-Table 13: Empirical vs. Retrained Dictionary Probabilities</section-marker>
      <section-marker initialCol="1" llx="64.0" lly="418.0" urx="256.0" ury="432.0" pageNum="6">2.4.4. Can the Weights in Dictionary be Bettered?</section-marker>
      <text initialCol="1" llx="49.0" lly="379.0" urx="310.0" ury="413.0" pageNum="6">Application of the decision tree model one phoneme at a time entails a conditional independence assumption between the surface forms given the baseforms, much as in a hiddenMarkovmodel (HMM).</text>
      <notext initialCol="1" llx="49.0" lly="368.0" urx="307.0" ury="382.0" pageNum="6">Thus the resultant probability of a pronunciation (obtained as a product</notext>
      <text initialCol="1" llx="49.0" lly="126.0" urx="302.0" ury="371.0" pageNum="6">of the conditional probabilities of the surface phones) is, at best, as reflective of the observed frequency of the pronunciation as the goodnessof this independenceassumption. To check this, we compared the probabilities of the pronunciations in the ICSI+TIMIT dictionary for afew hand-pickedwords with their relative frequency in our automatic transcriptions. Table 12 suggeststhat the tree probabilities, andperhapsthe independenceassumptionas well, are very unsatisfactory. Much room for research and improvement remains here. Since the Retrained trees were basedonmuch more data (which also happened to be the same data from which the empirical probabilities of the pronunciations were inferred), we conducted a similar comparison for the Retrained2 dictionary. The examplein Table 13 further reinforces our conclusion that it is the HMM-like independenceassumptionmore than the leaf probability estimation which skews the tree based pronunciation probabilities away from their empirically observed values. Alternative probability assignments at the surface string level should be investigated in the future. We also conductedan experiment, which clearly brings out the importance of correct pronunciation weight estimation even when the HMM-like independence assumption is made. Since we were not satisfied with the pronunciation probabilities of the ICSI+TIMIT trees, we poured the 60 hours of automatically transcribed data down</text>
      <text initialCol="1" llx="314.0" lly="712.0" urx="555.0" ury="762.0" pageNum="6">Dictionary Weights WER DEL SUB INS PronLex -- 44.66% 1987 5398 796 ICSI+TIMIT ICSI+TIMIT 46.14% 2134 5568 751 ICSI+TIMIT Retrained 44.05% 1982 5351 736</text>
      <text initialCol="1" llx="308.0" lly="589.0" urx="555.0" ury="705.0" pageNum="6">Table 14: Impact of Reestimating Pronunciation Tree Probabilities the trees and reestimated the leaf distributions, as described in the context of Table 6. These trees continued to assign mismatched pronunciation probabilities to words, much as above, but they had considerably better recognition performance, as indicated in Table 14. We were unable to investigate due to time limitations during the workshop why the three retrained trees help in spite of not always being in tune with empirical pronunciation frequencies.</text>
      <section-marker initialCol="1" llx="308.0" lly="566.0" urx="481.0" ury="580.0" pageNum="6">2.5. Summary of Tree Based Experiments</section-marker>
      <text initialCol="1" llx="325.0" lly="436.0" urx="558.0" ury="563.0" pageNum="6">ffl Pronunciation probabilities based on TIMIT trees for NAB helped performance (+1.9%) and reestimated trees helped more (+0.8%). ffl Pronunciation probabilities based on ICSI+TIMIT trees for Switchboard hurt performance (-1.5%), but those from reestimated trees help (+0.9%). ffl Reestimated pronunciation probabilities still don't agree with empirical frequencies in training. Word level pronunciation probabilities should be examined. ffl Words have variable tendencies to be mispronounced. All words in the dictionary should not be expanded equally.</text>
      <section-marker initialCol="1" llx="341.0" lly="412.0" urx="522.0" ury="426.0" pageNum="6">3. EXPLICIT DICTIONARY EXPANSION</section-marker>
      <text initialCol="1" llx="308.0" lly="320.0" urx="555.0" ury="406.0" pageNum="6">The degradation in performance due to the ICSI+TIMIT dictionary admits the possibility that the ICSI+TIMIT trees either generalize incorrectly or do a poor job of assigning costs to the alternate pronunciations. Both of these are crucial to the success of dictionary enhancement based methods. An alternate, more conservative approach to dictionary enhancement was therefore examined at WS97. As such, all experiments from here on apply to Switchboard.</text>
      <section-marker initialCol="1" llx="308.0" lly="296.0" urx="443.0" ury="311.0" pageNum="6">3.1. ICSI Multiword Dictionary</section-marker>
      <text initialCol="1" llx="308.0" lly="176.0" urx="556.0" ury="294.0" pageNum="6">ThePronLex dictionary is first enhancedwith all the pronunciations for words seen in the hand-labelled (ICSI) portion of the corpus. A candidate list of 172 multiwords (cf. [4]) is also appended to the dictionary to capture coarticulation, and pronunciations for these are similarly extended using the hand-labelled corpus. The word transcription of the training corpus is then expanded using these alternate pronunciations and aligned with the acoustics using our baselinemodels. New pronunciationswhich are chosensufficiently often are deemed bona fide entries to the ICSI Multiword dictionary; the others are discarded. Pronunciations are assigned weights based on their relative frequency.</text>
      <section-marker initialCol="1" llx="308.0" lly="153.0" urx="443.0" ury="167.0" pageNum="6">3.2. Auto Multiword Dictionary</section-marker>
      <text initialCol="1" llx="308.0" lly="126.0" urx="555.0" ury="150.0" pageNum="6">Instead of the forced alignment among alternate pronunciations extracted from the hand-labelled portion of the corpus as described</text>
      <notext initialCol="1" llx="70.0" lly="724.0" urx="274.0" ury="763.0" pageNum="7">Dictionary WER DEL SUB INS PronLex 44.7% 10.9% 29.5% 4.3% ICSI Multiword 44.6% 10.3% 29.7% 4.6%</notext>
      <section-marker initialCol="1" llx="70.0" lly="713.0" urx="274.0" ury="726.0" pageNum="7">Auto Multiword 43.8% 10.4% 29.1% 4.3%</section-marker>
      <section-marker initialCol="1" llx="49.0" lly="692.0" urx="295.0" ury="706.0" pageNum="7">Table 15: Lattice-Rescoring with Explicitly ExpandedDictionaries</section-marker>
      <text initialCol="1" llx="49.0" lly="596.0" urx="299.0" ury="682.0" pageNum="7">above,new pronunciationsfor words andmultiwords may bechosen from the large automatically transcribed corpus described in Section 2.2. This alternative approach yields the Auto Multiword dictionary. Qualitatively speaking, this dictionary invokesthe decision tree pronunciation models to generate alternatives, but keeps only those which occur frequently enough in the automatic transcription. Again, weights are assigned to each pronunciation based on its relative frequency.</text>
      <section-marker initialCol="1" llx="49.0" lly="572.0" urx="266.0" ury="586.0" pageNum="7">3.3. Recognition Results using Expanded Dictionaries</section-marker>
      <text initialCol="1" llx="49.0" lly="431.0" urx="297.0" ury="569.0" pageNum="7">Bigram lattices for the WS97 dev-test, generatedusing the PronLex dictionary, are rescored using the enhanced dictionaries described above. Table 15 shows recognition performance using the two dictionaries. The 0.9% improvement due to the Auto Multiword dictionary is encouraging, particularly in contrast to the lack of improvement obtained from the ICSI Multiword dictionary. This comparison further reinforces the impression that the hand-labelled data is good for bootstrapping, but not reliable enough for directly estimating pronunciation models. At the least, incorporation of human expert knowledge into statistical information processing systems has been shown again to be a difficult problem in which naive approachesdo not work as well as modelling techniques that match the supplied knowledge to the capabilties of the system.</text>
      <section-marker initialCol="1" llx="64.0" lly="406.0" urx="281.0" ury="420.0" pageNum="7">4. COARTICULATION SENSITIVE CLUSTERING</section-marker>
      <text initialCol="1" llx="49.0" lly="126.0" urx="299.0" ury="400.0" pageNum="7">Context dependentacoustic modelssuch as triphone HMMs are capable of implicitly modelling some allophonic variation. However, the models in our baseline system do not distinguish betweenwordinternal and cross-word triphones, and one may hypothesise that the gains above, especially those from the Multiword experiments, are due to better modelling of common cross-word effects. To investigate this possibility, the triphone clustering procedure in our (HTK) system is enhanced, as described next. The major deviation from the baseline system is to mark the phones in the the PronLex dictionary to permit acoustic triphone state clustering routines to make explicit use of information about word boundary location. Another important modification is the use of a specific interjection phone set. This is not so much to model interjections better as to prevent the very frequent interjections from overwhelming the clustering and modelling of phones in noninterjections. Acoustic model training is carried out in the same manner as the baseline system, with the difference that the question set for triphone state clustering is augmented with questions regarding the word boundary tags and interjection phone set. A set of acoustic models, named the INTWBD models, comparable to the baseline in terms of the number of states and Gaussian components, is thus estimated. Next, the training data is retranscribed using these models and the pronunciation networks of Section 2.2. The Retrained2 dictionary and the Auto Multiword dictionary of Sections 2.2 and 3.2 respectively are then regenerated from these transcriptions.</text>
      <notext initialCol="1" llx="329.0" lly="678.0" urx="533.0" ury="763.0" pageNum="7">Dictionary WER DEL SUB INS Baseline Acoustic Models PronLex 43.4% 9.8% 29.4% 4.1% INTWBD Acoustic Models PronLex 41.8% 10.1% 27.8% 3.9% Retrained2 41.3% 10.2% 27.5% 3.7% Auto Multiword 41.1% 9.7% 27.5% 4.0%</notext>
      <table-marker initialCol="1" llx="308.0" lly="385.0" urx="570.0" ury="671.0" pageNum="7">Table 16: Lattice-Rescoring with New AMs Dictionary WER DEL SUB INS Baseline Acoustic Models PronLex 40.9% 8.9% 27.8% 4.2% INTWBD Acoustic Models PronLex 39.4% 9.2% 26.2% 4.0% Retrained2 38.9% 9.2% 25.9% 3.8% Auto Multiword 38.5% 8.6% 25.8% 4.2% Table 17: Lattice-Rescoring with new AMs and a Trigram LM 4.1. Recognition Results Using Improved Acoustic Models Table 16 shows the results 4 of rescoring the WS97 dev-test set using the INTWBD acoustic models, and indicates that enabling the state clustering to take advantage of word boundary information and separate phones for interjections result in significant improvement in performance (1.6%). Observe that the two dictionary enhancementtechniquescontinue to provide addedimprovements (0.7%), though to a slightly smaller extent now. 5. LANGUAGE MODEL IMPROVEMENTS</table-marker>
      <text initialCol="1" llx="308.0" lly="191.0" urx="567.0" ury="374.0" pageNum="7">In the spirit of investigating whether pronunciation modelling via the two expandeddictionaries continues to be of benefit when other components of the system are improved, lattices generated by a bigram languagemodeland the baselinePronLex dictionary are rescored using a trigram language model and the Retrained2 and Auto Multiword dictionaries. The results in Table 17 are therefore directly comparablewith those in Table 16, which are basedon bigram scores. Observe that the improvement from the INTWBD models over the baseline models is 1.5%, which matches the 1.6% improvement with the bigram language model. The additional improvement of 0.5% from the Retrained2 dictionary also continues to hold, and the improvement from the Auto Multiword dictionary over the PronLex dictionary actually increases from 0.7% to 0.9%. All these results indicate that our straightforward pronunciation models and the coarticulation sensitive acoustic modelling provide gains which are additive to language model improvements.</text>
      <notext initialCol="1" llx="57.0" lly="127.0" urx="553.0" ury="763.0" pageNum="7">4 Though these results are for the same baseline system and test set, the baseline performance here differs slightly from the one shown in Tables 8 and 15. This is mostly due to a change in the acoustic segmentation of the test set between the two experiments, evidently for the better, and to a smaller extent due to a small change in the scoring software. Models WER DEL SUB INS Bigram LM INTWBD 41.8% 10.1% 27.8% 3.9% MWINTWBD 41.3% 9.6% 27.5% 4.2% Trigram LM INTWBD 39.4% 9.2% 26.2% 4.0% MWINTWBD 39.0% 8.7% 26.1% 4.2% Table 18: Lattice-Rescoring with Retrained Acoustic Models</notext>
      <section-marker initialCol="1" llx="89.0" lly="634.0" urx="256.0" ury="648.0" pageNum="8">6. ACOUSTIC MODEL RETRAINING</section-marker>
      <text initialCol="1" llx="49.0" lly="477.0" urx="304.0" ury="627.0" pageNum="8">The baseline as well as the INTWBD acoustic models are trained on the PronLex dictionary, prompting the concern that these models are not appropriate for use with the new dictionaries. In particular, given the prevalence of reduced variants in the new dictionaries, the acoustic contexts upon which the triphone states are clustered in the baseline system are suspectedto be poorly matched to the new dictionaries. This section describes a procedure used to retrain models better matched to the ICSI Multiword dictionary 5 . This work makes use of training techniques developed by the Hidden Pronunciation Mode group at the 1996 LVCSR Workshop. First, the state clustered triphone INTWBD models and the regenerated ICSI Multiword dictionary of Section 4 are used to obtain a phonetic transcription of the corpus, which then remains fixed during training. Untied triphones for this transcription are then cloned</text>
      <notext initialCol="1" llx="49.0" lly="467.0" urx="306.0" ury="480.0" pageNum="8">from the monophoneHMMs created during the training of the baseline</notext>
      <text initialCol="1" llx="49.0" lly="415.0" urx="295.0" ury="470.0" pageNum="8">system. Finally, the training procedure for the INTWBD models is mimicked starting with triphone HMM reestimation, followed by state clustering, etc.. The resulting HMMs, comparable in the number of states and Gaussian components to the baseline system, are called MWINTWBD models.</text>
      <section-marker initialCol="1" llx="49.0" lly="387.0" urx="282.0" ury="401.0" pageNum="8">6.1. Recognition Results using Retrained Acoustic Models</section-marker>
      <text initialCol="1" llx="49.0" lly="275.0" urx="296.0" ury="383.0" pageNum="8">Bigram lattices for the WS97 dev-test, generated using the baseline acoustic models and the PronLex dictionary, are rescored using the MWINTWBD acoustic models and the ICSI Multiword dictionary. Table 18 shows the results of the rescoring experiment. Recall from Table 15 that the ICSI Multiword dictionary gives essentially no gain by itself, and thus the gain here (0.4%) may be attributed to the acoustic retraining. It is expected that substantially higher gains will be attained by acoustic retraining with better phonetic transcription such as those obtained using the Auto Multiword dictionary.</text>
      <section-marker initialCol="1" llx="131.0" lly="247.0" urx="214.0" ury="261.0" pageNum="8">7. CONCLUSION</section-marker>
      <text initialCol="1" llx="49.0" lly="174.0" urx="296.0" ury="239.0" pageNum="8">This research suggests that significant improvement in speech recognition can be made by suitably modelling systematic pronunciation variation. Further, our results indicate that while a handlabelled corpus is very useful as a bootstrapping device, estimates of pronunciationprobabilities, context effects, etc., are best derived from larger amounts of automatic transcriptions, preferably done</text>
      <notext initialCol="1" llx="49.0" lly="127.0" urx="294.0" ury="166.0" pageNum="8">5 The acoustic retraining was not on our best (Auto Multiword) dictionary for historical reasons: the ICSI Multiword dictionary was obtained first, and a retraining effort was started before the superiority of the Auto Multiword dictionary was established.</notext>
      <text initialCol="1" llx="308.0" lly="653.0" urx="558.0" ury="770.0" pageNum="8">using the same set of acoustic modelswhich will eventually beused for recognition. On NAB, using pronunciation modelling with acoustic model retraining, we saw a 2.7% reduction in WER over a TTS baseline system. On Switchboard, without acoustic model retraining, we sawa 0.9% reduction in WER overa Pronlex baselinesystem, which is demonstrably additive to improvements in language (2.5%) and acoustic (1.5%) modelling, and to gains from adaptation (not reported here). Work is underway to develop effective acoustic model retraining methods for Switchboard when these statistical pronunciation lexicons are employed.</text>
    </body>
    <biblio>
      <reference initialCol="1" llx="312.0" lly="578.0" urx="555.0" ury="622.0" pageNum="8" refID="p8x312.0y609.0">
        <ref-marker initialCol="1" llx="312.0" lly="609.0" urx="376.0" ury="622.0" pageNum="8">[1]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="609.0" urx="400.0" ury="622.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="609.0" urx="376.0" ury="622.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="609.0" urx="376.0" ury="622.0" pageNum="8">W.</author-first>
            <author-last initialCol="1" llx="312.0" lly="609.0" urx="376.0" ury="622.0" pageNum="8">Byrne,</author-last>
          </author>
          et al,
        </authors>
        <reference-hlabeled initialCol="1" llx="394.0" lly="609.0" urx="555.0" ury="622.0" pageNum="8">"</reference-hlabeled>
        <title initialCol="1" llx="328.0" lly="598.0" urx="555.0" ury="622.0" pageNum="8">Pronunciation Modelling for Conversational Speech Recognition: A Status Report from WS97,"</title>
        <note initialCol="1" llx="328.0" lly="588.0" urx="555.0" ury="601.0" pageNum="8">presented at the</note>
        <date initialCol="1" llx="328.0" lly="588.0" urx="555.0" ury="601.0" pageNum="8">1997</date>
        <conference initialCol="1" llx="328.0" lly="578.0" urx="555.0" ury="601.0" pageNum="8">IEEE Workshop on Speech Recognition and Understanding,</conference>
        <address initialCol="1" llx="328.0" lly="578.0" urx="538.0" ury="591.0" pageNum="8">Santa Barbara, CA,</address>
        <date initialCol="1" llx="328.0" lly="578.0" urx="538.0" ury="591.0" pageNum="8">Dec. 1997.</date>
      </reference>
      <reference initialCol="1" llx="312.0" lly="542.0" urx="555.0" ury="577.0" pageNum="8" refID="p8x312.0y563.0">
        <ref-marker initialCol="1" llx="312.0" lly="563.0" urx="375.0" ury="577.0" pageNum="8">[2]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="563.0" urx="399.0" ury="577.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="563.0" urx="375.0" ury="577.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="563.0" urx="375.0" ury="577.0" pageNum="8">W.</author-first>
            <author-last initialCol="1" llx="312.0" lly="563.0" urx="375.0" ury="577.0" pageNum="8">Byrne,</author-last>
          </author>
          et al,
        </authors>
        <reference-hlabeled initialCol="1" llx="392.0" lly="563.0" urx="555.0" ury="577.0" pageNum="8">"</reference-hlabeled>
        <title initialCol="1" llx="328.0" lly="553.0" urx="555.0" ury="577.0" pageNum="8">Pronunciation Modelling Using a Handlabelled Corpus for Conversational Speech Recognition",</title>
        <conference initialCol="1" llx="328.0" lly="542.0" urx="403.0" ury="556.0" pageNum="8">Proc. ICASSP</conference>
        <date initialCol="1" llx="328.0" lly="542.0" urx="403.0" ury="556.0" pageNum="8">'98</date>
        <address initialCol="1" llx="395.0" lly="542.0" urx="450.0" ury="556.0" pageNum="8">Seattle, WA.</address>
      </reference>
      <reference initialCol="1" llx="312.0" lly="518.0" urx="555.0" ury="541.0" pageNum="8" refID="p8x312.0y528.0">
        <ref-marker initialCol="1" llx="312.0" lly="528.0" urx="555.0" ury="541.0" pageNum="8">[3]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="528.0" urx="555.0" ury="541.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="528.0" urx="555.0" ury="541.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="528.0" urx="555.0" ury="541.0" pageNum="8">F.</author-first>
            <author-last initialCol="1" llx="312.0" lly="528.0" urx="555.0" ury="541.0" pageNum="8">Chen,</author-last>
          </author>
        </authors>
        <title initialCol="1" llx="312.0" lly="518.0" urx="555.0" ury="541.0" pageNum="8">"Identification of Contextual Factors for Pronunciation Networks,"</title>
        <conference initialCol="1" llx="391.0" lly="518.0" urx="469.0" ury="531.0" pageNum="8">Proc. ICASSP `</conference>
        <date initialCol="1" llx="391.0" lly="518.0" urx="469.0" ury="531.0" pageNum="8">90,</date>
        <pages initialCol="1" llx="460.0" lly="518.0" urx="516.0" ury="531.0" pageNum="8">S14.9,</pages>
        <date initialCol="1" llx="460.0" lly="518.0" urx="516.0" ury="531.0" pageNum="8">1990.</date>
      </reference>
      <reference initialCol="1" llx="312.0" lly="482.0" urx="555.0" ury="517.0" pageNum="8" refID="p8x312.0y503.0">
        <ref-marker initialCol="1" llx="312.0" lly="503.0" urx="555.0" ury="517.0" pageNum="8">[4]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="503.0" urx="555.0" ury="517.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="503.0" urx="555.0" ury="517.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="503.0" urx="555.0" ury="517.0" pageNum="8">M.</author-first>
            <author-last initialCol="1" llx="312.0" lly="503.0" urx="555.0" ury="517.0" pageNum="8">Finke</author-last>
          </author>
          and
          <author initialCol="1" llx="312.0" lly="503.0" urx="555.0" ury="517.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="503.0" urx="555.0" ury="517.0" pageNum="8">A.</author-first>
            <author-last initialCol="1" llx="312.0" lly="503.0" urx="555.0" ury="517.0" pageNum="8">Waibel,</author-last>
          </author>
        </authors>
        <title initialCol="1" llx="312.0" lly="482.0" urx="555.0" ury="517.0" pageNum="8">"Speaker Mode Dependent Pronunciation Modelling in Large Vocabulary Conversational Speech Recognition,</title>
        <reference-hlabeled initialCol="1" llx="328.0" lly="482.0" urx="425.0" ury="496.0" pageNum="8">"</reference-hlabeled>
        <conference initialCol="1" llx="328.0" lly="482.0" urx="521.0" ury="496.0" pageNum="8">in Proc. EUROSPEECH</conference>
        <date initialCol="1" llx="418.0" lly="482.0" urx="543.0" ury="496.0" pageNum="8">'97, 1997.</date>
      </reference>
      <reference initialCol="1" llx="312.0" lly="457.0" urx="555.0" ury="481.0" pageNum="8" refID="p8x312.0y468.0">
        <ref-marker initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">[5]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">W.</author-first>
            <author-last initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">Fisher,</author-last>
          </author>
          <author initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">V.</author-first>
            <author-last initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">Zue,</author-last>
          </author>
          <author initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">J.</author-first>
            <author-last initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">Bernstein,</author-last>
          </author>
          and
          <author initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">D.</author-first>
            <author-last initialCol="1" llx="312.0" lly="468.0" urx="555.0" ury="481.0" pageNum="8">Pallet,</author-last>
          </author>
        </authors>
        <title initialCol="1" llx="312.0" lly="458.0" urx="555.0" ury="481.0" pageNum="8">"An AcousticPhonetic Data Base,"</title>
        <journal initialCol="1" llx="407.0" lly="458.0" urx="486.0" ury="471.0" pageNum="8">J. Acoust. Soc. Am.</journal>
        <volume initialCol="1" llx="478.0" lly="457.0" urx="499.0" ury="472.0" pageNum="8">81,</volume>
        <pages initialCol="1" llx="491.0" lly="458.0" urx="554.0" ury="471.0" pageNum="8">Suppl. 1,</pages>
        <date initialCol="1" llx="491.0" lly="458.0" urx="554.0" ury="471.0" pageNum="8">1987.</date>
      </reference>
      <reference initialCol="1" llx="312.0" lly="422.0" urx="555.0" ury="457.0" pageNum="8" refID="p8x312.0y443.0">
        <ref-marker initialCol="1" llx="312.0" lly="443.0" urx="555.0" ury="457.0" pageNum="8">[6]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="443.0" urx="555.0" ury="457.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="443.0" urx="555.0" ury="457.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="443.0" urx="555.0" ury="457.0" pageNum="8">S.</author-first>
            <author-last initialCol="1" llx="312.0" lly="443.0" urx="555.0" ury="457.0" pageNum="8">Greenberg,</author-last>
          </author>
        </authors>
        <reference-hlabeled initialCol="1" llx="312.0" lly="443.0" urx="555.0" ury="457.0" pageNum="8">"</reference-hlabeled>
        <title initialCol="1" llx="312.0" lly="433.0" urx="555.0" ury="457.0" pageNum="8">The Switchboard Transcription Project," 1996 LVCSR Summer Workshop Technical Reports,</title>
        <date initialCol="1" llx="525.0" lly="433.0" urx="555.0" ury="446.0" pageNum="8">1996,</date>
        <web initialCol="1" llx="329.0" lly="422.0" urx="540.0" ury="437.0" pageNum="8">http://www.icsi.berkeley.edu/real/stp/</web>
      </reference>
      <reference initialCol="1" llx="312.0" lly="397.0" urx="555.0" ury="422.0" pageNum="8" refID="p8x312.0y408.0">
        <ref-marker initialCol="1" llx="312.0" lly="408.0" urx="387.0" ury="421.0" pageNum="8">[7]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="408.0" urx="387.0" ury="421.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="408.0" urx="387.0" ury="421.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="408.0" urx="387.0" ury="421.0" pageNum="8">P.</author-first>
            <author-last initialCol="1" llx="312.0" lly="408.0" urx="387.0" ury="421.0" pageNum="8">Ladefoged,</author-last>
          </author>
        </authors>
        <booktitle initialCol="1" llx="379.0" lly="408.0" urx="472.0" ury="422.0" pageNum="8">A Course in Phonetics,</booktitle>
        <publisher initialCol="1" llx="328.0" lly="397.0" urx="555.0" ury="421.0" pageNum="8">Harcourt Brace Jovanovich, Inc.,</publisher>
        <address initialCol="1" llx="328.0" lly="397.0" urx="442.0" ury="411.0" pageNum="8">New York,</address>
        <date initialCol="1" llx="328.0" lly="397.0" urx="442.0" ury="411.0" pageNum="8">1975.</date>
      </reference>
      <reference initialCol="1" llx="312.0" lly="362.0" urx="555.0" ury="396.0" pageNum="8" refID="p8x312.0y383.0">
        <ref-marker initialCol="1" llx="312.0" lly="383.0" urx="555.0" ury="396.0" pageNum="8">[8]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="383.0" urx="555.0" ury="396.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="383.0" urx="555.0" ury="396.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="383.0" urx="555.0" ury="396.0" pageNum="8">M.</author-first>
            <author-last initialCol="1" llx="312.0" lly="383.0" urx="555.0" ury="396.0" pageNum="8">Randolph</author-last>
          </author>
        </authors>
        <reference-hlabeled initialCol="1" llx="312.0" lly="383.0" urx="555.0" ury="396.0" pageNum="8">"</reference-hlabeled>
        <title initialCol="1" llx="312.0" lly="373.0" urx="555.0" ury="396.0" pageNum="8">A Data-Driven Method for Discovering and Predicting Allophonic Variation,"</title>
        <conference initialCol="1" llx="449.0" lly="373.0" urx="526.0" ury="386.0" pageNum="8">Proc. ICASSP</conference>
        <date initialCol="1" llx="449.0" lly="373.0" urx="526.0" ury="386.0" pageNum="8">`90,</date>
        <pages initialCol="1" llx="517.0" lly="373.0" urx="555.0" ury="386.0" pageNum="8">S14.10,</pages>
        <date initialCol="1" llx="328.0" lly="362.0" urx="358.0" ury="376.0" pageNum="8">1990.</date>
      </reference>
      <reference initialCol="1" llx="312.0" lly="327.0" urx="555.0" ury="361.0" pageNum="8" refID="p8x312.0y348.0">
        <ref-marker initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">[9]</ref-marker>
        <authors initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">
          <author initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">M.</author-first>
            <author-last initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">Riley</author-last>
          </author>
          and
          <author initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">
            <author-first initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">A.</author-first>
            <author-last initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">Ljolje,</author-last>
          </author>
        </authors>
        <reference-hlabeled initialCol="1" llx="312.0" lly="348.0" urx="555.0" ury="361.0" pageNum="8">"</reference-hlabeled>
        <title initialCol="1" llx="312.0" lly="337.0" urx="555.0" ury="361.0" pageNum="8">Automatic generation of detailed pronunciation lexicons.</title>
        <reference-hlabeled initialCol="1" llx="328.0" lly="337.0" urx="426.0" ury="351.0" pageNum="8">"</reference-hlabeled>
        <journal initialCol="1" llx="328.0" lly="327.0" urx="555.0" ury="351.0" pageNum="8">Automatic Speech and Speaker Recognition: Advanced Topics.</journal>
        <publisher initialCol="1" llx="433.0" lly="327.0" urx="494.0" ury="340.0" pageNum="8">Kluwer.</publisher>
        <date initialCol="1" llx="433.0" lly="327.0" urx="494.0" ury="340.0" pageNum="8">1995.</date>
      </reference>
      <reference initialCol="1" llx="308.0" lly="292.0" urx="555.0" ury="326.0" pageNum="8" refID="p8x308.0y313.0">
        <ref-marker initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">[10]</ref-marker>
        <authors initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">
          <author initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">G.</author-first>
            <author-last initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">Tajchman,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">E.</author-first>
            <author-last initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">Fosler,</author-last>
          </author>
          and
          <author initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">D.</author-first>
            <author-last initialCol="1" llx="308.0" lly="313.0" urx="554.0" ury="326.0" pageNum="8">Jurafsky,</author-last>
          </author>
        </authors>
        <title initialCol="1" llx="308.0" lly="292.0" urx="555.0" ury="326.0" pageNum="8">"Building Multiple Pronunciation Models for Novel Words using Exploratory Computational Phonology",</title>
        <conference initialCol="1" llx="431.0" lly="292.0" urx="521.0" ury="305.0" pageNum="8">Proc. Eurospeech</conference>
        <date initialCol="1" llx="431.0" lly="292.0" urx="543.0" ury="305.0" pageNum="8">'95, 1995.</date>
      </reference>
      <reference initialCol="1" llx="308.0" lly="246.0" urx="556.0" ury="291.0" pageNum="8" refID="p8x308.0y277.0">
        <ref-marker initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">[11]</ref-marker>
        <authors initialCol="1" llx="308.0" lly="267.0" urx="555.0" ury="291.0" pageNum="8">
          <author initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">M.</author-first>
            <author-last initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">Weintraub,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">E.</author-first>
            <author-last initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">Fosler,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">C.</author-first>
            <author-last initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">Galles,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">Y.</author-first>
            <author-last initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">Kao,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">S.</author-first>
            <author-last initialCol="1" llx="308.0" lly="277.0" urx="555.0" ury="291.0" pageNum="8">Khudanpur,</author-last>
          </author>
          <author initialCol="1" llx="328.0" lly="267.0" urx="555.0" ury="280.0" pageNum="8">
            <author-first initialCol="1" llx="328.0" lly="267.0" urx="555.0" ury="280.0" pageNum="8">M.</author-first>
            <author-last initialCol="1" llx="328.0" lly="267.0" urx="555.0" ury="280.0" pageNum="8">Saraclar,</author-last>
          </author>
          <author initialCol="1" llx="328.0" lly="267.0" urx="555.0" ury="280.0" pageNum="8">
            <author-first initialCol="1" llx="328.0" lly="267.0" urx="555.0" ury="280.0" pageNum="8">S.</author-first>
            <author-last initialCol="1" llx="328.0" lly="267.0" urx="555.0" ury="280.0" pageNum="8">Wegmann,</author-last>
          </author>
        </authors>
        <reference-hlabeled initialCol="1" llx="328.0" lly="267.0" urx="555.0" ury="280.0" pageNum="8">"</reference-hlabeled>
        <title initialCol="1" llx="328.0" lly="256.0" urx="555.0" ury="280.0" pageNum="8">Automatic Learning of Word Pronunciation from Data,"</title>
        <conference initialCol="1" llx="328.0" lly="246.0" urx="556.0" ury="270.0" pageNum="8">1996 LVCSR Summer Workshop Technical Reports,</conference>
        <date initialCol="1" llx="397.0" lly="246.0" urx="427.0" ury="260.0" pageNum="8">1996.</date>
      </reference>
      <reference initialCol="1" llx="308.0" lly="201.0" urx="555.0" ury="245.0" pageNum="8" refID="p8x308.0y232.0">
        <ref-marker initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">[12]</ref-marker>
        <authors initialCol="1" llx="308.0" lly="221.0" urx="555.0" ury="245.0" pageNum="8">
          <author initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">M.</author-first>
            <author-last initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">Weintraub,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">H.</author-first>
            <author-last initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">Murveit,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">M.</author-first>
            <author-last initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">Cohen,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">P.</author-first>
            <author-last initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">Price,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="221.0" urx="555.0" ury="245.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="232.0" urx="555.0" ury="245.0" pageNum="8">J.</author-first>
            <author-last initialCol="1" llx="308.0" lly="221.0" urx="555.0" ury="245.0" pageNum="8">Bernstein,</author-last>
          </author>
          <author initialCol="1" llx="328.0" lly="221.0" urx="555.0" ury="235.0" pageNum="8">
            <author-first initialCol="1" llx="328.0" lly="221.0" urx="555.0" ury="235.0" pageNum="8">C.</author-first>
            <author-last initialCol="1" llx="328.0" lly="221.0" urx="555.0" ury="235.0" pageNum="8">Baldwin,</author-last>
          </author>
          <author initialCol="1" llx="328.0" lly="221.0" urx="555.0" ury="235.0" pageNum="8">
            <author-first initialCol="1" llx="328.0" lly="221.0" urx="555.0" ury="235.0" pageNum="8">D.</author-first>
            <author-last initialCol="1" llx="328.0" lly="221.0" urx="555.0" ury="235.0" pageNum="8">Bell,</author-last>
          </author>
        </authors>
        <reference-hlabeled initialCol="1" llx="328.0" lly="221.0" urx="555.0" ury="235.0" pageNum="8">"</reference-hlabeled>
        <title initialCol="1" llx="328.0" lly="211.0" urx="555.0" ury="235.0" pageNum="8">Linguistic Constraints in Hidden Markov Model Based Speech Recognition,"</title>
        <conference initialCol="1" llx="493.0" lly="211.0" urx="555.0" ury="225.0" pageNum="8">Proc. ICASSP</conference>
        <date initialCol="1" llx="328.0" lly="201.0" urx="353.0" ury="214.0" pageNum="8">'89,</date>
        <pages initialCol="1" llx="344.0" lly="201.0" urx="400.0" ury="214.0" pageNum="8">S13.2,</pages>
        <date initialCol="1" llx="344.0" lly="201.0" urx="400.0" ury="214.0" pageNum="8">1989.</date>
      </reference>
      <reference initialCol="1" llx="308.0" lly="165.0" urx="555.0" ury="200.0" pageNum="8" refID="p8x308.0y186.0">
        <ref-marker initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">[13]</ref-marker>
        <authors initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">
          <author initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">S.</author-first>
            <author-last initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">Young,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">J.</author-first>
            <author-last initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">Jansen,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">J.</author-first>
            <author-last initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">Odell,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">D.</author-first>
            <author-last initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">Ollasen,</author-last>
          </author>
          <author initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">
            <author-first initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">P.</author-first>
            <author-last initialCol="1" llx="308.0" lly="186.0" urx="555.0" ury="200.0" pageNum="8">Woodland,</author-last>
          </author>
        </authors>
        <title initialCol="1" llx="328.0" lly="176.0" urx="444.0" ury="190.0" pageNum="8">The HTK Book (Version 2.0),</title>
        <institution initialCol="1" llx="328.0" lly="165.0" urx="555.0" ury="189.0" pageNum="8">Entropic Cambridge Research Laboratory,</institution>
        <date initialCol="1" llx="328.0" lly="165.0" urx="402.0" ury="179.0" pageNum="8">1995.</date>
      </reference>
    </biblio>
  </content>
  <CitationContexts />
  <grants />
</document>

